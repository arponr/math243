\documentclass{amsart}
\usepackage{graphicx, subcaption}
\usepackage{fancyhdr}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=black
}

\frenchspacing

\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\fancyhead{}
\fancyfoot[C]{\ \\\small\thepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{2pt}

\renewcommand{\labelitemi}{---}
\renewcommand{\labelitemii}{--}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title[Simulating indirect reciprocity using PageRank]{Simulating
  Evolution of Indirect Reciprocity \\ with Reputation using PageRank}  
\author{Arpon Raksit --- Math 243 --- \today}

\begin{document}

\begin{abstract}
An interesting question in evolutionary dynamics is understanding how
indirect reciprocity might emerge, that is, how individuals might
evolve a tendency to accept a cost in exchange for another
individual's benefit, without the understanding that the other will
later repay them. A natural mechanism for evolving indirect
reciprocity is a reputation system: donating to others enhances one's
reputation, and one is more likely to donate to those with higher
reputation. We develop a novel model for determining reputation,
adapted from the PageRank Web search algorithm, which naturally values
the opinions of selfish individuals less than generous individuals
when calculating reputation. Using this model, we find that
cooperation can emerge with much significantly benefit/cost ratios
than previously observed.
\end{abstract}

\maketitle
\thispagestyle{fancy}

\section{Introduction}

In studying the evolutionary origins of altruistic behavior, one of
the most common mechanisms considered is that of reciprocity: an
individual accepts a cost to itself in order to grant a greater
benefit to another. In the most intuitive versions of reciprocity, the
payback (in the form of a reciprocal donation) is immediate; that is,
the players are playing some iterated game where non-cooperation can
immediately be punished. However, ``in the wild'' we often observe
even more altruistic behavior, in which an individual sacrifices some
fitness even when it is not guaranteed that the beneficiary will ever
have the ability to reciprocate, under the assumption that other
members of the population will do a similar service to the donor. This
type of interaction is termed ``indirect reciprocity'' and there are
several proposed mechanisms for it.

We consider the mechanism of reputation: when an individual chooses to
donate, it enhances their reputation in the population, and
individuals are more likely to donate to individuals with higher
reputation. Although reputation is one of the most obvious mechanisms
for indirect reciprocity, many models suffer from certain
game-theoretic problems. One is that individuals are often penalized
equally for being selfish no matter the reputation of their opponent,
so that if an otherwise generous player has the bad luck to be paired
against several sociopaths, their reputation will be penalized
unfairly. Also, Leimar and Hammerstein \cite{leimar_evolution_2001}
argue that in many reputational models, the dominant strategy is to
consider only one's own reputation and not the recipient's, and
allowing strategies of this form threatens the evolutionary stability
of cooperative ones. We try to find a model that limits these effects.

To that end, we adapt the PageRank algorithm from Web searching to
give a reputation score to each individual based on the matrix of
pairwise opinions of each individual about each other. These opinions
are based on the most recent interaction between the two. We give a
stochastic model for the evolutionary dynamics of a population
undergoing reputation interactions using such scoring, and give some
arguments as to why this model is realistic and avoids the problems
mentioned above.

Using this model, we show that indirect reciprocity can emerge in
large populations with a much lower benefit/cost ratio than previously
shown. We show that altruism can spontaneously emerge and fixate even
in large populations of reasonably selfish individuals. We also show
that our model is quite robust: even in the presence of significantly
reduced information (high probability that interactions are not
recorded), cooperation can still emerge. Finally, we obtain the
counterintuitive result that with some reasonable parameter values,
the probability of cooperation fixating actually increases for larger
populations.

The rest of the paper is organized as follows: in
\S\ref{section-related}, we go over previous work and explain our
novel contributions. In \S\ref{section-model}, we describe our model
and explain our parameter choices; in \S\ref{section-analysis}, we
motivate and justify some of our choices and give some analysis of our
model. In \S\ref{section-results}, we describe and analyze the results
of our simulations. Finally, in \S\ref{section-conclusion} we draw
conclusions and in \S\ref{section-further} we suggest further avenues
of research.

\subsection{Acknowledgements}

Most of this model was developed last semester in collaboration with
Ben Kuhn and Rahul Dalal. My work this semester is essentially in
\begin{enumerate}
\item correcting an error in our use of the PageRank algorithm;
\item obtaining new and more data with this correction;
\item explaining a result we found confusing, but finding another
  confusing result.
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{section-related}

An initial model of indirect reciprocity was suggested by Boyd and
Richerson \cite{boyd_evolution_1989}. In this model, individuals are
arranged in a ring and each individual picks the strategy ``all
defect'', ``upstream tit-for-tat'' (donate unless your potential donor
is selfish) or ``downstream tit-for-tat'' (donate unless your
recipient is selfish). In this model, Boyd and Richerson found that
reciprocal strategies require relatively high concentrations before
they are evolutionarily favored. They also found that downstream
tit-for-tat was generally much more successful than upstream
tit-for-tat, suggesting that strategies based on the recipient's
reputation are more favorable evolutionarily and indicating that
reputation-based systems may be worthy of consideration.

Nowak and Sigmund have modeled indirect reciprocity with a concept of
``image'' \cite{nowak_evolution_1998}. Each individual in the
simulation is given an image score. During each round of a stochastic
simulation, individuals play a number of single-round donor-receiver
games with other members of the population and have the opportunity to
be either altruistic or selfish; the former increases the image score
and the latter decreases it. Individuals’ strategies are to donate if
the recipient’s image score is above some threshold, but keep the
reward otherwise.

Under these circumstances, Nowak and Sigmund found that in the
simplest model, without mutation, whether cooperation evolves is
determined by the initial fraction of defectors. Adding mutation
causes the population to cycle between discriminating cooperation,
unconditional cooperation, and defection in all cases. Limiting the
number of interactions known by each player makes it difficult to
establish cooperation in large populations. Finally, if players are
conscious of their own reputation and act to increase it when it is
low, cooperation evolves much more easily.

This model is simple and elegant, but it has a few drawbacks. For
instance, it discretizes reputation, which may lead to strange edge
effects. Furthermore, it penalizes equally an individual who defects
because they are playing against a low-reputation opponent, and one
who defects for selfish reasons. Finally, Leimar and Hammerstein
\cite{leimar_evolution_2001} argue that in this model the
evolutionarily dominant strategy is to consider only one's own
reputation and not the recipients, and allowing these strategies
threatens the evolutionary stability of cooperative ones.

One can compensate for the latter two problems by considering not just
``first-order'' strategies (that only depend on the donor's actions)
but also second-order strategies (depending on the recipient's current
reputation) and third-order (depending on the donor's current
reputation).  Using a simpler model, in which individuals are rated on
a binary scale of either ``good'' or ``bad,'' Ohtsuki and Ikawa
\cite{ohtsuki_how_2004} showed that out of all 4,096 third-order
strategies, there are a ``leading eight'' that are significantly more
evolutionarily stable than any others, and all of these take into
account that defection against bad actors should not be penalized.

In our model, as in Ohtsuki and Ikawa's ``leading eight,'' players are
not penalized for refusing to donate to selfish recipients.
Furthermore, we allow for a richer scale of reputation than a binary
good/bad rating, and our model can be extended in many ways to take
into account more complex behavior.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Our model}
\label{section-model}

The model comprises a sequence of rounds in which a number of
donor-receiver games are played.

\subsection{Parameters}
\label{subsection-parameters}

Our model has the following parameters:

\begin{itemize}
\item $N \in \mathbb{N}$, population size;
\item $I \in \mathbb{N}$, number of donor-receiver interactions per round.
\item $b \in [1, \infty)$, benefit-to-cost ratio (relative fitness
  benefit to recipient).
\item $\omega \in (0, \infty)$, intensity of selection (magnitude of
  cost to donor).
\item $\mu \in [0, 1]$, strategy mutation probability.
\item $c \in [0, 1]$, probability (at initialisation or mutation) of individual
  being unconditional cooperator;
\item $d \in [0, 1-c]$, probability (at initialisation or mutation) of
  individual being unconditional defector;
\item $\alpha \in (0,1]$, a ``teleportation probability'' used in
  computing PageRank (see \S\ref{subsection-pagerank});
\item $\tau \in \mathbb{N}$, number of iterations used in computing
  PageRank.
\end{itemize}

\subsection{State}
\label{subsection-state}

The state of our model at any time is characterised by the following
objects: 
\begin{itemize}
\item $M = (M_{ij})$, an $N \times N$ binary matrix representing the
  opinions each individual has of the others---$M_{ij} = 1$ if player
  $i$ donated to $j$ the last time they had the chance, and $M_{ij} =
  0$ if $i$ was selfish;
\item $f \in [0, \infty)^N$, the fitness vector of the population;
\item $r \in [0,1]^N$, the reputation vector of the population
  (determined by $M$, as detailed below);
\item $s \in [-c,1+d]^N$, the strategy vector of the population.
\end{itemize}
The initial state is given by
\begin{itemize}
\item $M_{ij} = 0$ for $1 \le i,j \le N$;
\item $s_i$ uniformly at random from $[-c,1+d]$ for $1 \le i \le N$;
\item $f_i = 1$ for $1 \le i \le n$.
\end{itemize}

\subsection{Round protocol}
\label{subsection-round}

Each round is comprised of the following steps:

\begin{enumerate}
\item compute $r$ from $M$ according to the PageRank algorithm
  (see \S\ref{subsection-pagerank}).
\item execute $I$ interactions, where in each interaction we
  (independently):
  \begin{enumerate}
  \item choose the ``donor'' $1 \le i \le N$ uniformly at random;
  \item choose the ``receiver'' $1 \le j \le N, j \ne i$ uniformly at
    random;
  \item if $s_i < r_j$, ``cooperation'' occurs: $f_i$ decreases by
    $\omega$, $f_j$ increases by $b\omega$, and $M_{ij}$ is set to
    $1$.
  \item else, ``defection'' occurs: $M_{ij}$ is set to $0$.
  \end{enumerate}
\item choose $1 \le u \le N$ to ``die'' uniformly at random;
\item choose $1 \le v \le N$ to ``reproduce'' with probability
  proportional to $f_v$.
\item ``replace $u$ with the offspring of $v$'', that is:
  \begin{enumerate}
  \item for $1 \le i \le N$ let $M_{ui} = M_{vi}$ and $M_{iu} =
    M_{iv}$, with the exception that we keep $M_{uu} = 0$;
  \item let $f_u = f_v$;
  \item with probability $\mu$, choose $s_u$ uniformly randomly as in
    the initial state, and with probability $1-\mu$ let $s_u = s_v$.
  \end{enumerate}
\end{enumerate}

\subsection{PageRank}
\label{subsection-pagerank}

The intuition here is that we can view $M$ as a directed graph, with
an edge from $j$ to $i$ (representing that $j$ has ``endorsed'' $i$)
if and only if $M_{ij} = 1$. Noting an analogy between these
endorsements and links between web pages, we run the standard PageRank
algorithm \cite{page_pagerank_1999} on this graph. (See
\S{section-whypagerank} for an explanation of why this is a realistic
algorithm for individuals to employ.)

Given $M$, we compute $r$ by PageRank as follows. Let $\tilde M =
(\tilde M_{ij})$ the following column-normalisation of $M$:
\[
\tilde M_{ij} =
\begin{cases}
  1/N, & \sum_{k=0}^N M_{kj} = 0; \\ 
  \alpha M_{ij} / \sum_{k=0}^N M_{kj} + (1-\alpha)/N, & \text{otherwise};
\end{cases}
\]
for $1 \le i,j \le N$. The idea of PageRank is to treat this
column-stochastic matrix $\tilde M$ as a Markov chain and find its
stationary probability. The Perron-Frobenius theorem implies that
$\tilde M$ has a unique non-negative eigenvector (and therefore a
unique PageRank vector) if and only if it is irreducible. And indeed
irreducibility is ensured here by the ``teleportation probability''
$\alpha$.

Thus we can compute PageRank using the iterated multiplication method.
That is, let $r_0$ the uniform vector $(1/N,\ldots,1/N)$, and let $r_i =
\tilde M^i r_0$ for $1 \le i \le \tau$. Then $r_\tau$ is (an
approximation to) the PageRank.

We make one modification to the PageRank algorithm to compute
$r$. Note $r_\tau$ is normalized to be stochastic, and thus gives a
relative notion of reputation. But since strategies are absolute,
reputation needs to be as well. (For example, PageRank by itself does
not distinguish between the entire population cooperating and the
entire population defecting.) Therefore, we finally let
\[
r_k = \min\left(1,\sum_{1 \le i,j \le N} \frac{M_{ij}}{N-1}(r_\tau)_k\right)
\]
for $1 \le k \le n$. Here, $0 \le \sum_{1 \le i,j \le N} M_{ij} \le
(N-1)^2$ is a measure of how cooperative the current population is.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Analysis of model}
\label{section-analysis}

\subsection{Donation Game}

As in the model of Nowak and Sigmund \cite{nowak_evolution_1998}, we
use the one-shot donation game in order to minimise effects of direct
reciprocity.

\subsection{Use of PageRank}
\label{section-whypagerank}

The PageRank algorithm is frequently used to calculate reputation in
social networks \cite{pujol_extracting_2002}, and has an important
property which makes it a natural candidate for our setting:
\begin{itemize}
\item
The opinions of more generous players matter more. This is because
more generous players have more endorsements pointing to them, and
thus better reputation; therefore an endorsement from a high-raking
individual confers more reputation on the receiver than a reputation
from a lower individual. For this reason, optimal strategies must take
into account the receiver's reputation as well as the donor's,
resolving Leimar and Hammerstein's complaint
\cite{leimar_evolution_2001} that reputation dynamics do not properly
incentivize players.
\item
A nice consequence of this is that the effects of selfishness against
low-ranked individuals are minimised: low-reputation groups cannot
unilaterally affect the PageRank graph by a large margin
\cite{langville_deeper_2004}. Therefore, generous individuals will not
be unduly penalized for encountering a number of selfish individuals
and refusing to cooperate.
\end{itemize}

\subsection{Interactions per round}
\label{section-inter_per_round}

It is a convention in many models to have every member of the
population interact every round of the simulation. However, to study
the regime in which direct reciprocity plays no significant role, we
chose instead to pick a fixed number of random pairs of members to
interact. 

Specifically, in a population of $N$, since one player dies every
round, each player dies with probability $1/N$ and so a player's
lifespan is a geometrically distributed random variable with mean
$N$. If we pick $I=N$, then on any given round and for any given
players $A$ and $B$, player $A$ interacts with $B$ with probability
$1/N$. Therefore if $I\le N$ we expect on average at most one
interaction between any two given players before one dies. This should
be enough to minimize the effects of our model proxying direct
reciprocity.

\subsection{Reference implementation}
\label{section-implementation}

We implemented our simulation in Python using SciPy, NumPy, Weave, and
Matplotlib. A Git repository of our implementation can be found at
\url{https://github.com/arponr/math243}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{section-results}

Throughout our experiments we use $b=5$, $\omega=.1$, $\mu=.0001$,
$c=d=.05$, and $\tau=10$ (except in).

\subsection{Dependence on interactions per round}

We first examine how, for fixed population size, varying the number of
interactions per round affects the amount of cooperation that
occurs. To do this, for $N \in \{20,50,100\}$ and $I \in
\{10,20,50,100,200\}$, we plot a histogram of the proportion of
cooperative interactions for the first $10000$ rounds, over $50$
trials (Figures \ref{figure-N20}--\subref{figure-N100}).

It is evident that the absorbption rate of cooperation increases as
$I$ increases, for each $N$. This is expected, since a larger number
of interactions per round:
\begin{enumerate}
\item increases the potential effects of proxying
  direct reciprocity (see \S\ref{section-inter_per_round});
\item means that the opinion matrix more closely reflects the current
  strategy distribution, and thus a player's reputation is a better
  indicator of their current cooperativeness, as shown in Figures
  \ref{figure-track50}--\subref{figure-track200}.
\end{enumerate}

\begin{figure}[h!tbp]  
  \begin{subfigure}{.485\linewidth}
    \centering
    \includegraphics[width=\linewidth]{N20.png}
    \caption{$N=20$}
    \label{figure-N20}
  \end{subfigure}
  \hspace{.01\linewidth}
  \begin{subfigure}{.485\linewidth}  
    \centering
    \includegraphics[width=\linewidth]{N50.png}
    \caption{$N=50$}
    \label{figure-N50}
  \end{subfigure}
  \begin{subfigure}{.485\linewidth}
    \centering
    \includegraphics[width=\linewidth]{N100.png}
    \caption{$N=100$}
    \label{figure-N100}
  \end{subfigure}
  \caption{Histograms of proportion of cooperation over $10000$ rounds,
    varying $I \in \{10,20,50,100,200\}$}
\end{figure}

\begin{figure}[h!tbp]
  \begin{subfigure}{.485\linewidth}
    \includegraphics[width=\linewidth]{track50.png}
    \caption{$I=50$}
    \label{figure-track50}
  \end{subfigure}
  \hspace{.01\linewidth}
  \begin{subfigure}{.485\linewidth}
    \includegraphics[width=\linewidth]{track200.png}
    \caption{$I=200$}
    \label{figure-track200}
  \end{subfigure}
\caption{A comparison of average number of cooperations (red) and
  average reputation (green) with $N=100$ over $10000$ steps. Clearly
  when the number of interactions higher, average reputation tracks
  current average cooperativeness much more closely.}
\end{figure}

\subsection{Dependence on population size}
\label{section-pop_size}

We next examine the effect of varying $N \in \{10, 20, 50, 100,
200\}$, while keeping $I=N$, on cooperativity. Figure
\ref{figure-NeqM} shows the results in the same way as in the previous
section. We see that cooperativity increases as $N=I$ increases, and
indeed this makes sense. An equivalent way of stating this result is
that the necessary number of interactions $I$ to achieve a given
proportion of cooperation is sublinear in $N$. Recall from our
analysis in \S\ref{section-inter_per_round} that we need $N=I$ if we
want each individual to interact with each other individual once on
average. This result is saying then that it is unnecessary for all
individuals to act with each other, as they receive enough information
in reputation via other individuals' opinions.

\begin{figure}[h!tbp]
    \centering
    \includegraphics[width=.485\linewidth]{NeqM.png}
    \caption{Histograms of proportion of cooperation over $10000$
      rounds with $N=I \in \{10,20,50,100,200\}$}
    \label{figure-NeqM}
\end{figure}

\subsection{Long-range behavior}
\label{section-longrange}

Over hundreds of thousands of rounds the typical behavior can be
seen in Figure \ref{figure-long}.

\begin{figure}[h!tbp]
  \includegraphics[width=.6\linewidth]{long.png}
  \caption{Behaviour over $10^6$ rounds}
  \label{figure-long}
\end{figure}

Recall that strategy being less than reputation indicates
cooperativity, so each of these trial demonstrates high absorbptive
rate of cooperativity. This replicates Sigmund and Nowak's result
\cite{nowak_evolution_1998}, although with a much lower benefit/cost
ratio than used in that model. 

Note also that in one trial, cooperation takes over after defection is
stable, with strategy ending up below $0$. This indicates that
cooperation can dominate after a critical mass of unconditional
cooperators kickstarts an increase in reputations and average strategy
falls below zero as everyone becomes an unconditional cooperator by
random drift. Of course the existence of unconditional defectors
allows the opposite to occur as well.

\subsection{Number of PageRank iterations}

We finally examine how, for fixed population size, varying the number
of iterations in the PageRank computation affects the amount of
cooperation that occurs. We do this in the same way as previous
sections, with $N=I \in \{20,100\}$ and varying $\tau \in
\{1,2,5,10,20\}$. The results are found in Figures
\ref{figure-iterN20}--\subref{figure-iterN100}.

\begin{figure}[h!tbp]
  \begin{subfigure}{.485\linewidth}
    \includegraphics[width=\linewidth]{iterN20.png}
    \caption{$N=I=20$}
    \label{figure-iterN20}
  \end{subfigure}
  \hspace{.01\linewidth}
  \begin{subfigure}{.485\linewidth}
    \includegraphics[width=\linewidth]{iterN100.png}
    \caption{$N=I=100$}
    \label{figure-iterN100}
  \end{subfigure}
\caption{Histograms of proportion of cooperation over $10000$
      rounds with $\tau \in \{1,2,5,10,20\}$}
\end{figure}

Evidently the number of PageRank iterations has almost no impact on
cooperativity over the first 10000 rounds. This is quite surprising:
for example, one iteration of PageRank does not have at all the
motivating property of discounting the opinions of selfish individuals
when calculating reputation. Our only hope for making sense of this is
that we need to consider the model over a longer period of time, but
alas we did not have this longer period of time (or computational
power) to test this hypothesis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\label{section-conclusion}

We have developed a model for reputation dynamics with the following
benefits:

\begin{itemize}
\item properly aligned incentives (optimal strategies consider the
  recipient's reputation);
\item no bad penalties (e.g. against generous individuals not donating
  to selfish ones);
\item robust to incomplete information;
\item a rich reputation scale (not just ``good'' and ``bad'' or a few
  integers);
\item a well-motivated algorithmic mechanism.
\end{itemize}

This model achieves evolution of indirect reciprocity in many
realistic scenarios, including much more realistic benefit/cost ratios
than previously observed. Furthermore, it shows the same ``cycling''
behavior observed in other models at large timescales
\cite{nowak_evolution_1998}.

Obviously there are many more variables in this model than we had time
or computational power to analyze. It certainly merits further
investigation to determine its full behavior, extend it, and find all
the connections between various parameters, and there are still some
unknowns (such as the strange lack of dependence on the number of
PageRank iterations discussed above). We include some ideas for
further work below.

\section{Further directions}
\label{section-further}

\subsection{More data}

The model we created is highly stochastic and we did not have
sufficient time or computational power to run as many simulations as
we would have liked, given the number of parameters and variants.

\subsection{Analytic results}

Because of the nontrivial way in which past interactions affect the
current round, analytic results on this model seem rather
difficult. There exist mathematical bounds on PageRank obtained by
Bianchini et al. \cite{bianchini_Inside_2005} and Langville et
al. \cite{langville_deeper_2004}, which may suggest that some
theoretical results may be possible, but this is not clear at all. It
would probably be fruitful to somehow simplify the model in order to
do some precise analysis.

\subsection{Potential modifications}

We considered, but did not implement, a few other modifications to our
model:
\begin{description}
\item[Errors] There is a small probability $\alpha$ that a player does
  the opposite of what it wants to in an interaction.
\item[Blank slate] When an individual reproduces, all players'
  opinions of the offspring, and the offspring's opinions of each
  player, are reset (to 0, 1, random values or some default value).
\item[Grudges] When an $M_{ij}$ entry is updated a weighted average
  with some weight $m$ is taken with the new value and the old value
  representing some memory of past interactions.
\end{description}

\subsection{Third-order strategies}

Currently, the strategies that we consider only involve the
recipient's reputation. Nowak and Sigmund \cite{nowak_evolution_1998}
found that if donors were allowed to consider their own reputation as
well, cooperation evolved much faster. Our model could be extended
with such strategies as well.

\subsection{Lying}

Our model could be extended with a second set of strategies and
decisions by allowing recipients to lie about their opinions of
donors. This would add another layer of complexity, but the
evolutionary dynamics of lying and subterfuge have not heretofore been
well-studied, and our model might provide a good testing ground.

\subsection{Constrained computation}

In reality, it is not free to compute a PageRank vector with arbitrary
precision. It would be interesting to see if limiting the precision to
which the vector was calculated has any effect on how quickly or how
often cooperative strategies fixate in the population. In fact, this
could even be an additional feature subject to evolution and mutation.

\subsection{Limited knowledge}

For an individual to hold the entire opinion matrix in memory costs an
amount of memory quadratic in the number of individuals in the
population. It might be realistic to require that individuals only
know some minor of the full opinion matrix, with fitness costs
associated with knowing more of the matrix. If there are diminishing
returns to knowing more of the matrix, then there will be some
evolutionary equilibrium where fitness is maximized. With appropriate
fitness costs, one might even be able to obtain theoretical validation
for Dunbar's number, the number of individuals beyond which social
groups start to break down \cite{dunbar_neocortex_1995}.

\bibliographystyle{plain} \bibliography{refs}

\end{document}
